{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "395e236b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tvm\n",
    "from tvm import te, auto_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d35c08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@auto_scheduler.register_workload  # Note the auto_scheduler decorator\n",
    "def matmul_add(N, L, M, dtype):\n",
    "    A = te.placeholder((N, L), name=\"A\", dtype=dtype)\n",
    "    B = te.placeholder((L, M), name=\"B\", dtype=dtype)\n",
    "    C = te.placeholder((N, M), name=\"C\", dtype=dtype)\n",
    "\n",
    "    k = te.reduce_axis((0, L), name=\"k\")\n",
    "    matmul = te.compute(\n",
    "        (N, M),\n",
    "        lambda i, j: te.sum(A[i, k] * B[k, j], axis=k),\n",
    "        name=\"matmul\",\n",
    "        attrs={\"layout_free_placeholders\": [B]},  # enable automatic layout transform for tensor B\n",
    "    )\n",
    "    out = te.compute((N, M), lambda i, j: matmul[i, j] + C[i, j], name=\"out\")\n",
    "\n",
    "    return [A, B, C, out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c785f141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational DAG:\n",
      "A = PLACEHOLDER [1024, 1024]\n",
      "B = PLACEHOLDER [1024, 1024]\n",
      "matmul(i, j) += (A[i, k]*B[k, j])\n",
      "C = PLACEHOLDER [1024, 1024]\n",
      "out(i, j) = (matmul[i, j] + C[i, j])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target = tvm.target.Target(\"llvm -mcpu=core-avx2\")\n",
    "N = L = M = 1024\n",
    "task = tvm.auto_scheduler.SearchTask(func=matmul_add, args=(N, L, M, \"float32\"), target=target)\n",
    "\n",
    "# Inspect the computational graph\n",
    "print(\"Computational DAG:\")\n",
    "print(task.compute_dag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc7b3773",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = \"matmul.json\"\n",
    "tune_option = auto_scheduler.TuningOptions(\n",
    "    num_measure_trials=10,\n",
    "    measure_callbacks=[auto_scheduler.RecordToFile(log_file)],\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e69863f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Search ]\n",
      "----------------------------------------------------------------------\n",
      "Generate Sketches\t\t#s: 3\n",
      "Sample Initial Population\t#s: 2020\tfail_ct: 1\tTime elapsed: 0.28\n",
      "GA Iter: 0\tMax score: 0.9997\tMin score: 0.9464\t#Pop: 128\t#M+: 0\t#M-: 0\n",
      "GA Iter: 4\tMax score: 0.9999\tMin score: 0.9868\t#Pop: 128\t#M+: 1369\t#M-: 76\n",
      "EvolutionarySearch\t\t#s: 128\tTime elapsed: 1.17\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Measure ]\n",
      "----------------------------------------------------------------------\n",
      "Get 10 programs to measure:\n",
      ".........."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:48:12] /home/wendell/Desktop/tvm/src/runtime/threading_backend.cc:320: Warning: more than two frequencies detected!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "==================================================\n",
      "No: 1\tGFLOPS: 64.05 / 64.05\tresults: MeasureResult(cost:[0.0335], error_no:0, all_cost:0.42, Tstamp:1658202492.87)\n",
      "==================================================\n",
      "Placeholder: A, B, C\n",
      "parallel i.0@j.0@i.1@j.1@ (0,64)\n",
      "  matmul auto_unroll: 16\n",
      "  for k.0 (0,32)\n",
      "    for i.2 (0,4)\n",
      "      for j.2 (0,256)\n",
      "        for k.1 (0,32)\n",
      "          for i.3 (0,8)\n",
      "            vectorize j.3 (0,2)\n",
      "              matmul = ...\n",
      "  for i.2 (0,32)\n",
      "    for j.2 (0,512)\n",
      "      out = ...\n",
      "\n",
      "==================================================\n",
      "No: 2\tGFLOPS: 110.46 / 110.46\tresults: MeasureResult(cost:[0.0195], error_no:0, all_cost:0.42, Tstamp:1658202493.14)\n",
      "==================================================\n",
      "Placeholder: A, B, C\n",
      "parallel i.0@j.0@ (0,256)\n",
      "  for j.1 (0,2)\n",
      "    matmul auto_unroll: 16\n",
      "    for k.0 (0,16)\n",
      "      for i.2 (0,8)\n",
      "        for j.2 (0,32)\n",
      "          for k.1 (0,64)\n",
      "            vectorize j.3 (0,8)\n",
      "              matmul = ...\n",
      "    for i.2 (0,8)\n",
      "      for j.2 (0,256)\n",
      "        out = ...\n",
      "\n",
      "==================================================\n",
      "No: 3\tGFLOPS: 101.34 / 110.46\tresults: MeasureResult(cost:[0.0212], error_no:0, all_cost:0.41, Tstamp:1658202493.41)\n",
      "==================================================\n",
      "Placeholder: A, B, C\n",
      "parallel i.0 (0,4)\n",
      "  for j.0 (0,2)\n",
      "    for j.1 (0,8)\n",
      "      for k.0 (0,256)\n",
      "        for i.2 (0,256)\n",
      "          for j.2 (0,4)\n",
      "            for k.1 (0,4)\n",
      "              vectorize j.3 (0,16)\n",
      "                matmul = ...\n",
      "parallel i (0,1024)\n",
      "  for j (0,1024)\n",
      "    out = ...\n",
      "\n",
      "==================================================\n",
      "No: 4\tGFLOPS: 48.56 / 110.46\tresults: MeasureResult(cost:[0.0442], error_no:0, all_cost:0.33, Tstamp:1658202493.66)\n",
      "==================================================\n",
      "Placeholder: A, B, C\n",
      "parallel i.0@j.0@i.1@j.1@ (0,128)\n",
      "  for k.0 (0,1024)\n",
      "    for i.2 (0,512)\n",
      "      for j.2 (0,4)\n",
      "        vectorize j.3 (0,4)\n",
      "          matmul = ...\n",
      "  for i.2 (0,512)\n",
      "    for j.2 (0,16)\n",
      "      out = ...\n",
      "\n",
      "==================================================\n",
      "No: 5\tGFLOPS: 20.37 / 110.46\tresults: MeasureResult(cost:[0.1055], error_no:0, all_cost:0.60, Tstamp:1658202494.16)\n",
      "==================================================\n",
      "Placeholder: A, B, C\n",
      "parallel i.0@j.0@i.1@j.1@ (0,1024)\n",
      "  matmul auto_unroll: 64\n",
      "  for k.0 (0,64)\n",
      "    for i.2 (0,512)\n",
      "      for k.1 (0,16)\n",
      "        for i.3 (0,2)\n",
      "          matmul = ...\n",
      "  for i.2 (0,1024)\n",
      "    out = ...\n",
      "\n",
      "==================================================\n",
      "No: 6\tGFLOPS: 56.76 / 110.46\tresults: MeasureResult(cost:[0.0379], error_no:0, all_cost:0.38, Tstamp:1658202494.39)\n",
      "==================================================\n",
      "Placeholder: A, B, C\n",
      "parallel i.0@j.0@ (0,512)\n",
      "  matmul auto_unroll: 16\n",
      "  for i.1 (0,8)\n",
      "    for k.0 (0,64)\n",
      "      for i.2 (0,16)\n",
      "        for j.2 (0,8)\n",
      "          for k.1 (0,16)\n",
      "            vectorize j.3 (0,2)\n",
      "              matmul = ...\n",
      "  for i.1 (0,128)\n",
      "    vectorize j.1 (0,16)\n",
      "      out = ...\n",
      "\n",
      "==================================================\n",
      "No: 7\tGFLOPS: 37.15 / 110.46\tresults: MeasureResult(cost:[0.0578], error_no:0, all_cost:0.41, Tstamp:1658202494.69)\n",
      "==================================================\n",
      "Placeholder: A, B, C\n",
      "parallel i.0@j.0@i.1@ (0,128)\n",
      "  for j.1 (0,8)\n",
      "    for k.0 (0,32)\n",
      "      for i.2 (0,2)\n",
      "        for j.2 (0,64)\n",
      "          for k.1 (0,32)\n",
      "            for i.3 (0,4)\n",
      "              vectorize j.3 (0,2)\n",
      "                matmul = ...\n",
      "    for i.2 (0,8)\n",
      "      for j.2 (0,128)\n",
      "        out = ...\n",
      "\n",
      "==================================================\n",
      "No: 8\tGFLOPS: 80.42 / 110.46\tresults: MeasureResult(cost:[0.0267], error_no:0, all_cost:0.78, Tstamp:1658202494.97)\n",
      "==================================================\n",
      "Placeholder: A, B, C\n",
      "matmul auto_unroll: 64\n",
      "parallel i.0@j.0@i.1@j.1@ (0,128)\n",
      "  for k.0 (0,256)\n",
      "    for i.2 (0,2)\n",
      "      for j.2 (0,16)\n",
      "        for k.1 (0,4)\n",
      "          for i.3 (0,4)\n",
      "            for j.3 (0,64)\n",
      "              matmul = ...\n",
      "parallel i (0,1024)\n",
      "  for j (0,1024)\n",
      "    out = ...\n",
      "\n",
      "==================================================\n",
      "No: 9\tGFLOPS: 100.81 / 110.46\tresults: MeasureResult(cost:[0.0213], error_no:0, all_cost:0.38, Tstamp:1658202495.24)\n",
      "==================================================\n",
      "Placeholder: A, B, C\n",
      "matmul auto_unroll: 16\n",
      "parallel i.0@j.0@ (0,256)\n",
      "  for j.1 (0,8)\n",
      "    for k.0 (0,128)\n",
      "      for i.2 (0,8)\n",
      "        for j.2 (0,4)\n",
      "          for k.1 (0,8)\n",
      "            for i.3 (0,4)\n",
      "              vectorize j.3 (0,4)\n",
      "                matmul = ...\n",
      "parallel i (0,1024)\n",
      "  for j (0,1024)\n",
      "    out = ...\n",
      "\n",
      "==================================================\n",
      "No: 10\tGFLOPS: 35.21 / 110.46\tresults: MeasureResult(cost:[0.0610], error_no:0, all_cost:0.38, Tstamp:1658202495.56)\n",
      "==================================================\n",
      "Placeholder: A, B, C\n",
      "parallel i.0@j.0@ (0,4)\n",
      "  matmul auto_unroll: 16\n",
      "  for k.0 (0,1024)\n",
      "    for i.2 (0,128)\n",
      "      for j.2 (0,16)\n",
      "        for i.3 (0,2)\n",
      "          for j.3 (0,64)\n",
      "            matmul = ...\n",
      "  for i.1 (0,256)\n",
      "    for j.1 (0,1024)\n",
      "      out = ...\n",
      "\n",
      "Time elapsed for measurement: 3.94 s\n",
      "----------------------------------------------------------------------\n",
      "------------------------------  [ Done ]\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run auto-tuning (search)\n",
    "task.tune(tune_option)\n",
    "# Apply the best schedule\n",
    "sch, args = task.apply_best(log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d17c33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowered TIR:\n",
      "@main = primfn(A_1: handle, B_1: handle, C_1: handle, out_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [1048576], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [1048576], []),\n",
      "             C: Buffer(C_2: Pointer(float32), float32, [1048576], []),\n",
      "             out: Buffer(out_2: Pointer(float32), float32, [1048576], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, C_1: C, out_1: out}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [1024, 1024], []), B_1: B_3: Buffer(B_2, float32, [1024, 1024], []), C_1: C_3: Buffer(C_2, float32, [1024, 1024], []), out_1: out_3: Buffer(out_2, float32, [1024, 1024], [])} {\n",
      "  allocate(auto_scheduler_layout_transform: Pointer(global float32), float32, [1048576]), storage_scope = global;\n",
      "  allocate(matmul: Pointer(global float32), float32, [1048576]), storage_scope = global {\n",
      "    for (ax0.ax1.fused.ax2.fused: int32, 0, 16384) \"parallel\" {\n",
      "      for (ax3: int32, 0, 4) {\n",
      "        for (ax4: int32, 0, 2) {\n",
      "          for (ax5: int32, 0, 8) {\n",
      "            auto_scheduler_layout_transform_1: Buffer(auto_scheduler_layout_transform, float32, [1048576], [])[((((ax0.ax1.fused.ax2.fused*64) + (ax3*16)) + (ax4*8)) + ax5)] = B[(((((floormod(ax0.ax1.fused.ax2.fused, 512)*2048) + (ax4*1024)) + (floordiv(ax0.ax1.fused.ax2.fused, 512)*32)) + (ax3*8)) + ax5)]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    for (i.outer.outer.outer.j.outer.outer.outer.fused.i.outer.outer.inner.fused: int32, 0, 16384) \"parallel\" {\n",
      "      let cse_var_1: int32 = ((floormod(i.outer.outer.outer.j.outer.outer.outer.fused.i.outer.outer.inner.fused, 512)*2048) + (floordiv(i.outer.outer.outer.j.outer.outer.outer.fused.i.outer.outer.inner.fused, 512)*32))\n",
      "       {\n",
      "        matmul_1: Buffer(matmul, float32, [1048576], [])[ramp(cse_var_1, 1, 8)] = broadcast(0f32, 8)\n",
      "        matmul_1[ramp((cse_var_1 + 1024), 1, 8)] = broadcast(0f32, 8)\n",
      "        matmul_1[ramp((cse_var_1 + 8), 1, 8)] = broadcast(0f32, 8)\n",
      "        matmul_1[ramp((cse_var_1 + 1032), 1, 8)] = broadcast(0f32, 8)\n",
      "        matmul_1[ramp((cse_var_1 + 16), 1, 8)] = broadcast(0f32, 8)\n",
      "        matmul_1[ramp((cse_var_1 + 1040), 1, 8)] = broadcast(0f32, 8)\n",
      "        matmul_1[ramp((cse_var_1 + 24), 1, 8)] = broadcast(0f32, 8)\n",
      "        matmul_1[ramp((cse_var_1 + 1048), 1, 8)] = broadcast(0f32, 8)\n",
      "        for (k.outer: int32, 0, 512) {\n",
      "          let cse_var_20: int32 = (cse_var_1 + 8)\n",
      "          let cse_var_19: int32 = (cse_var_1 + 24)\n",
      "          let cse_var_18: int32 = (cse_var_1 + 16)\n",
      "          let cse_var_17: int32 = (cse_var_1 + 1048)\n",
      "          let cse_var_16: int32 = (cse_var_1 + 1040)\n",
      "          let cse_var_15: int32 = (cse_var_1 + 1032)\n",
      "          let cse_var_14: int32 = (cse_var_1 + 1024)\n",
      "          let cse_var_13: int32 = ((floormod(i.outer.outer.outer.j.outer.outer.outer.fused.i.outer.outer.inner.fused, 512)*2048) + (k.outer*2))\n",
      "          let cse_var_12: int32 = ((floordiv(i.outer.outer.outer.j.outer.outer.outer.fused.i.outer.outer.inner.fused, 512)*32768) + (k.outer*64))\n",
      "          let cse_var_11: int32 = (cse_var_13 + 1025)\n",
      "          let cse_var_10: int32 = (cse_var_13 + 1024)\n",
      "          let cse_var_9: int32 = (cse_var_13 + 1)\n",
      "          let cse_var_8: int32 = (cse_var_12 + 8)\n",
      "          let cse_var_7: int32 = (cse_var_12 + 56)\n",
      "          let cse_var_6: int32 = (cse_var_12 + 48)\n",
      "          let cse_var_5: int32 = (cse_var_12 + 40)\n",
      "          let cse_var_4: int32 = (cse_var_12 + 32)\n",
      "          let cse_var_3: int32 = (cse_var_12 + 24)\n",
      "          let cse_var_2: int32 = (cse_var_12 + 16)\n",
      "           {\n",
      "            matmul_1[ramp(cse_var_1, 1, 8)] = (matmul_1[ramp(cse_var_1, 1, 8)] + (broadcast(A[cse_var_13], 8)*auto_scheduler_layout_transform_1[ramp(cse_var_12, 1, 8)]))\n",
      "            matmul_1[ramp(cse_var_14, 1, 8)] = (matmul_1[ramp(cse_var_14, 1, 8)] + (broadcast(A[cse_var_10], 8)*auto_scheduler_layout_transform_1[ramp(cse_var_12, 1, 8)]))\n",
      "            matmul_1[ramp(cse_var_1, 1, 8)] = (matmul_1[ramp(cse_var_1, 1, 8)] + (broadcast(A[cse_var_9], 8)*auto_scheduler_layout_transform_1[ramp(cse_var_8, 1, 8)]))\n",
      "            matmul_1[ramp(cse_var_14, 1, 8)] = (matmul_1[ramp(cse_var_14, 1, 8)] + (broadcast(A[cse_var_11], 8)*auto_scheduler_layout_transform_1[ramp(cse_var_8, 1, 8)]))\n",
      "            matmul_1[ramp(cse_var_20, 1, 8)] = (matmul_1[ramp(cse_var_20, 1, 8)] + (broadcast(A[cse_var_13], 8)*auto_scheduler_layout_transform_1[ramp(cse_var_2, 1, 8)]))\n",
      "            matmul_1[ramp(cse_var_15, 1, 8)] = (matmul_1[ramp(cse_var_15, 1, 8)] + (broadcast(A[cse_var_10], 8)*auto_scheduler_layout_transform_1[ramp(cse_var_2, 1, 8)]))\n",
      "            matmul_1[ramp(cse_var_20, 1, 8)] = (matmul_1[ramp(cse_var_20, 1, 8)] + (broadcast(A[cse_var_9], 8)*auto_scheduler_layout_transform_1[ramp(cse_var_3, 1, 8)]))\n",
      "            matmul_1[ramp(cse_var_15, 1, 8)] = (matmul_1[ramp(cse_var_15, 1, 8)] + (broadcast(A[cse_var_11], 8)*auto_scheduler_layout_transform_1[ramp(cse_var_3, 1, 8)]))\n",
      "            matmul_1[ramp(cse_var_18, 1, 8)] = (matmul_1[ramp(cse_var_18, 1, 8)] + (broadcast(A[cse_var_13], 8)*auto_scheduler_layout_transform_1[ramp(cse_var_4, 1, 8)]))\n",
      "            matmul_1[ramp(cse_var_16, 1, 8)] = (matmul_1[ramp(cse_var_16, 1, 8)] + (broadcast(A[cse_var_10], 8)*auto_scheduler_layout_transform_1[ramp(cse_var_4, 1, 8)]))\n",
      "            matmul_1[ramp(cse_var_18, 1, 8)] = (matmul_1[ramp(cse_var_18, 1, 8)] + (broadcast(A[cse_var_9], 8)*auto_scheduler_layout_transform_1[ramp(cse_var_5, 1, 8)]))\n",
      "            matmul_1[ramp(cse_var_16, 1, 8)] = (matmul_1[ramp(cse_var_16, 1, 8)] + (broadcast(A[cse_var_11], 8)*auto_scheduler_layout_transform_1[ramp(cse_var_5, 1, 8)]))\n",
      "            matmul_1[ramp(cse_var_19, 1, 8)] = (matmul_1[ramp(cse_var_19, 1, 8)] + (broadcast(A[cse_var_13], 8)*auto_scheduler_layout_transform_1[ramp(cse_var_6, 1, 8)]))\n",
      "            matmul_1[ramp(cse_var_17, 1, 8)] = (matmul_1[ramp(cse_var_17, 1, 8)] + (broadcast(A[cse_var_10], 8)*auto_scheduler_layout_transform_1[ramp(cse_var_6, 1, 8)]))\n",
      "            matmul_1[ramp(cse_var_19, 1, 8)] = (matmul_1[ramp(cse_var_19, 1, 8)] + (broadcast(A[cse_var_9], 8)*auto_scheduler_layout_transform_1[ramp(cse_var_7, 1, 8)]))\n",
      "            matmul_1[ramp(cse_var_17, 1, 8)] = (matmul_1[ramp(cse_var_17, 1, 8)] + (broadcast(A[cse_var_11], 8)*auto_scheduler_layout_transform_1[ramp(cse_var_7, 1, 8)]))\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    for (i: int32, 0, 1024) \"parallel\" {\n",
      "      for (j: int32, 0, 1024) {\n",
      "        let cse_var_21: int32 = ((i*1024) + j)\n",
      "        out[cse_var_21] = (matmul_1[cse_var_21] + C[cse_var_21])\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Lowered TIR:\")\n",
    "print(tvm.lower(sch, args, simple_mode=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4300823e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:48:15] /home/wendell/Desktop/tvm/src/runtime/threading_backend.cc:320: Warning: more than two frequencies detected!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time of this operator: 0.007376 s\n"
     ]
    }
   ],
   "source": [
    "func = tvm.build(sch, args, target)\n",
    "a_np = np.random.uniform(size=(N, L)).astype(np.float32)\n",
    "b_np = np.random.uniform(size=(L, M)).astype(np.float32)\n",
    "c_np = np.random.uniform(size=(N, M)).astype(np.float32)\n",
    "out_np = a_np.dot(b_np) + c_np\n",
    "\n",
    "dev = tvm.cpu()\n",
    "a_tvm = tvm.nd.array(a_np, device=dev)\n",
    "b_tvm = tvm.nd.array(b_np, device=dev)\n",
    "c_tvm = tvm.nd.array(c_np, device=dev)\n",
    "out_tvm = tvm.nd.empty(out_np.shape, device=dev)\n",
    "func(a_tvm, b_tvm, c_tvm, out_tvm)\n",
    "\n",
    "# Check results\n",
    "np.testing.assert_allclose(out_np, out_tvm.numpy(), rtol=1e-3)\n",
    "\n",
    "# Evaluate execution time.\n",
    "evaluator = func.time_evaluator(func.entry_name, dev, min_repeat_ms=500)\n",
    "print(\n",
    "    \"Execution time of this operator: %f s\"\n",
    "    % (np.median(evaluator(a_tvm, b_tvm, c_tvm, out_tvm).results))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9a5ac89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equivalent python schedule:\n",
      "matmul_i, matmul_j, matmul_k = tuple(matmul.op.axis) + tuple(matmul.op.reduce_axis)\n",
      "out_i, out_j = tuple(out.op.axis) + tuple(out.op.reduce_axis)\n",
      "matmul_i_o_i, matmul_i_i = s[matmul].split(matmul_i, factor=2)\n",
      "matmul_i_o_o_i, matmul_i_o_i = s[matmul].split(matmul_i_o_i, factor=1)\n",
      "matmul_i_o_o_o, matmul_i_o_o_i = s[matmul].split(matmul_i_o_o_i, factor=512)\n",
      "matmul_j_o_i, matmul_j_i = s[matmul].split(matmul_j, factor=8)\n",
      "matmul_j_o_o_i, matmul_j_o_i = s[matmul].split(matmul_j_o_i, factor=4)\n",
      "matmul_j_o_o_o, matmul_j_o_o_i = s[matmul].split(matmul_j_o_o_i, factor=1)\n",
      "matmul_k_o, matmul_k_i = s[matmul].split(matmul_k, factor=2)\n",
      "s[matmul].reorder(matmul_i_o_o_o, matmul_j_o_o_o, matmul_i_o_o_i, matmul_j_o_o_i, matmul_k_o, matmul_i_o_i, matmul_j_o_i, matmul_k_i, matmul_i_i, matmul_j_i)\n",
      "s[out].compute_root()\n",
      "matmul_i_o_o_o_j_o_o_o_fused_i_o_o_i_fused = s[matmul].fuse(matmul_i_o_o_o, matmul_j_o_o_o, matmul_i_o_o_i)\n",
      "s[matmul].parallel(matmul_i_o_o_o_j_o_o_o_fused_i_o_o_i_fused)\n",
      "s[out].parallel(out_i)\n",
      "s[matmul].pragma(matmul_i_o_o_o_j_o_o_o_fused_i_o_o_i_fused, \"auto_unroll_max_step\", 512)\n",
      "s[matmul].pragma(matmul_i_o_o_o_j_o_o_o_fused_i_o_o_i_fused, \"unroll_explicit\", True)\n",
      "s[matmul].vectorize(matmul_j_i)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Equivalent python schedule:\")\n",
    "print(task.print_best(log_file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
