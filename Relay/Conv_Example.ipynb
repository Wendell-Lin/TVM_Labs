{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc960824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tvm\n",
    "from tvm import te\n",
    "\n",
    "# The sizes of inputs and filters\n",
    "batch = 8\n",
    "in_channel = 256\n",
    "out_channel = 512\n",
    "in_size = 14\n",
    "kernel = 3\n",
    "pad = 1\n",
    "stride = 1\n",
    "\n",
    "# Algorithm\n",
    "A = te.placeholder((in_size, in_size, in_channel, batch), name=\"A\")\n",
    "W = te.placeholder((kernel, kernel, in_channel, out_channel), name=\"W\")\n",
    "out_size = (in_size - kernel + 2 * pad) // stride + 1\n",
    "# Pad input\n",
    "Apad = te.compute(\n",
    "    (in_size + 2 * pad, in_size + 2 * pad, in_channel, batch),\n",
    "    lambda yy, xx, cc, nn: tvm.tir.if_then_else(\n",
    "        tvm.tir.all(yy >= pad, yy - pad < in_size, xx >= pad, xx - pad < in_size),\n",
    "        A[yy - pad, xx - pad, cc, nn],\n",
    "        tvm.tir.const(0.0, \"float32\"),\n",
    "    ),\n",
    "    name=\"Apad\",\n",
    ")\n",
    "# Create reduction variables\n",
    "rc = te.reduce_axis((0, in_channel), name=\"rc\")\n",
    "ry = te.reduce_axis((0, kernel), name=\"ry\")\n",
    "rx = te.reduce_axis((0, kernel), name=\"rx\")\n",
    "# Compute the convolution\n",
    "B = te.compute(\n",
    "    (out_size, out_size, out_channel, batch),\n",
    "    lambda yy, xx, ff, nn: te.sum(\n",
    "        Apad[yy * stride + ry, xx * stride + rx, rc, nn] * W[ry, rx, rc, ff], axis=[ry, rx, rc]\n",
    "    ),\n",
    "    name=\"B\",\n",
    ")\n",
    "s = te.create_schedule(B.op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f08cf66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolution: 3560.534293 ms\n"
     ]
    }
   ],
   "source": [
    "func = tvm.build(s, [A, W, B], \"llvm\")\n",
    "dev = tvm.cpu()\n",
    "a_np = np.random.uniform(size=(in_size, in_size, in_channel, batch)).astype(A.dtype)\n",
    "w_np = np.random.uniform(size=(kernel, kernel, in_channel, out_channel)).astype(W.dtype)\n",
    "a = tvm.nd.array(a_np, dev)\n",
    "w = tvm.nd.array(w_np, dev)\n",
    "b = tvm.nd.array(np.zeros((out_size, out_size, out_channel, batch), dtype=B.dtype), dev)\n",
    "func(a, w, b)\n",
    "evaluator = func.time_evaluator(func.entry_name, dev, number=1)\n",
    "print(\"Convolution: %f ms\" % (evaluator(a, w, b).mean * 1e3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0acf5e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@main = primfn(A_1: handle, W_1: handle, B_1: handle) -> ()\n",
      "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [401408], []),\n",
      "             W: Buffer(W_2: Pointer(float32), float32, [1179648], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [802816], [])}\n",
      "  buffer_map = {A_1: A, W_1: W, B_1: B}\n",
      "  preflattened_buffer_map = {A_1: A_3: Buffer(A_2, float32, [14, 14, 256, 8], []), W_1: W_3: Buffer(W_2, float32, [3, 3, 256, 512], []), B_1: B_3: Buffer(B_2, float32, [14, 14, 512, 8], [])} {\n",
      "  allocate(Apad: Pointer(global float32), float32, [524288]), storage_scope = global {\n",
      "    for (yy: int32, 0, 16) {\n",
      "      for (xx: int32, 0, 16) {\n",
      "        for (cc: int32, 0, 256) {\n",
      "          for (nn: int32, 0, 8) {\n",
      "            let cse_var_2: int32 = (xx*2048)\n",
      "            let cse_var_1: int32 = (cc*8)\n",
      "            Apad_1: Buffer(Apad, float32, [524288], [])[((((yy*32768) + cse_var_2) + cse_var_1) + nn)] = @tir.if_then_else(((((1 <= yy) && (yy < 15)) && (1 <= xx)) && (xx < 15)), A[(((((yy*28672) + cse_var_2) + cse_var_1) + nn) - 30720)], 0f32, dtype=float32)\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    for (yy_1: int32, 0, 14) {\n",
      "      for (xx_1: int32, 0, 14) {\n",
      "        for (ff: int32, 0, 512) {\n",
      "          for (nn_1: int32, 0, 8) {\n",
      "            B[((((yy_1*57344) + (xx_1*4096)) + (ff*8)) + nn_1)] = 0f32\n",
      "            for (ry: int32, 0, 3) {\n",
      "              for (rx: int32, 0, 3) {\n",
      "                for (rc: int32, 0, 256) {\n",
      "                  let cse_var_3: int32 = ((((yy_1*57344) + (xx_1*4096)) + (ff*8)) + nn_1)\n",
      "                  B[cse_var_3] = (B[cse_var_3] + (Apad_1[((((((yy_1*32768) + (ry*32768)) + (xx_1*2048)) + (rx*2048)) + (rc*8)) + nn_1)]*W[((((ry*393216) + (rx*131072)) + (rc*512)) + ff)]))\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tvm.lower(s, [A, W, B], simple_mode=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3f000e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
