{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7023101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tvm import relay\n",
    "from tvm.relay import testing\n",
    "import tvm\n",
    "from tvm import te\n",
    "from tvm.contrib import graph_executor\n",
    "import tvm.testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf29747f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#[version = \"0.0.5\"]\n",
      "def @main(%data: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] */, %conv1_1_weight: Tensor[(64, 3, 3, 3), float32] /* ty=Tensor[(64, 3, 3, 3), float32] */, %conv1_1_bias: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %conv2_1_weight: Tensor[(128, 64, 3, 3), float32] /* ty=Tensor[(128, 64, 3, 3), float32] */, %conv2_1_bias: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, %conv3_1_weight: Tensor[(256, 128, 3, 3), float32] /* ty=Tensor[(256, 128, 3, 3), float32] */, %conv3_1_bias: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %conv3_2_weight: Tensor[(256, 256, 3, 3), float32] /* ty=Tensor[(256, 256, 3, 3), float32] */, %conv3_2_bias: Tensor[(256), float32] /* ty=Tensor[(256), float32] */, %conv4_1_weight: Tensor[(512, 256, 3, 3), float32] /* ty=Tensor[(512, 256, 3, 3), float32] */, %conv4_1_bias: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %conv4_2_weight: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %conv4_2_bias: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %conv5_1_weight: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %conv5_1_bias: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %conv5_2_weight: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */, %conv5_2_bias: Tensor[(512), float32] /* ty=Tensor[(512), float32] */, %fc6_weight: Tensor[(4096, 25088), float32] /* ty=Tensor[(4096, 25088), float32] */, %fc6_bias: Tensor[(4096), float32] /* ty=Tensor[(4096), float32] */, %fc7_weight: Tensor[(4096, 4096), float32] /* ty=Tensor[(4096, 4096), float32] */, %fc7_bias: Tensor[(4096), float32] /* ty=Tensor[(4096), float32] */, %fc8_weight: Tensor[(1000, 4096), float32] /* ty=Tensor[(1000, 4096), float32] */, %fc8_bias: Tensor[(1000), float32] /* ty=Tensor[(1000), float32] */) -> Tensor[(1, 1000), float32] {\n",
      "  %0 = nn.conv2d(%data, %conv1_1_weight, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 224, 224), float32] */;\n",
      "  %1 = nn.bias_add(%0, %conv1_1_bias) /* ty=Tensor[(1, 64, 224, 224), float32] */;\n",
      "  %2 = nn.relu(%1) /* ty=Tensor[(1, 64, 224, 224), float32] */;\n",
      "  %3 = nn.max_pool2d(%2, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
      "  %4 = nn.conv2d(%3, %conv2_1_weight, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 112, 112), float32] */;\n",
      "  %5 = nn.bias_add(%4, %conv2_1_bias) /* ty=Tensor[(1, 128, 112, 112), float32] */;\n",
      "  %6 = nn.relu(%5) /* ty=Tensor[(1, 128, 112, 112), float32] */;\n",
      "  %7 = nn.max_pool2d(%6, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 128, 56, 56), float32] */;\n",
      "  %8 = nn.conv2d(%7, %conv3_1_weight, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
      "  %9 = nn.bias_add(%8, %conv3_1_bias) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
      "  %10 = nn.relu(%9) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
      "  %11 = nn.conv2d(%10, %conv3_2_weight, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
      "  %12 = nn.bias_add(%11, %conv3_2_bias) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
      "  %13 = nn.relu(%12) /* ty=Tensor[(1, 256, 56, 56), float32] */;\n",
      "  %14 = nn.max_pool2d(%13, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 256, 28, 28), float32] */;\n",
      "  %15 = nn.conv2d(%14, %conv4_1_weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
      "  %16 = nn.bias_add(%15, %conv4_1_bias) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
      "  %17 = nn.relu(%16) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
      "  %18 = nn.conv2d(%17, %conv4_2_weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
      "  %19 = nn.bias_add(%18, %conv4_2_bias) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
      "  %20 = nn.relu(%19) /* ty=Tensor[(1, 512, 28, 28), float32] */;\n",
      "  %21 = nn.max_pool2d(%20, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
      "  %22 = nn.conv2d(%21, %conv5_1_weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
      "  %23 = nn.bias_add(%22, %conv5_1_bias) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
      "  %24 = nn.relu(%23) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
      "  %25 = nn.conv2d(%24, %conv5_2_weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
      "  %26 = nn.bias_add(%25, %conv5_2_bias) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
      "  %27 = nn.relu(%26) /* ty=Tensor[(1, 512, 14, 14), float32] */;\n",
      "  %28 = nn.max_pool2d(%27, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
      "  %29 = nn.batch_flatten(%28) /* ty=Tensor[(1, 25088), float32] */;\n",
      "  %30 = nn.dense(%29, %fc6_weight, units=4096) /* ty=Tensor[(1, 4096), float32] */;\n",
      "  %31 = nn.bias_add(%30, %fc6_bias, axis=-1) /* ty=Tensor[(1, 4096), float32] */;\n",
      "  %32 = nn.relu(%31) /* ty=Tensor[(1, 4096), float32] */;\n",
      "  %33 = nn.dropout(%32) /* ty=(Tensor[(1, 4096), float32], Tensor[(1, 4096), float32]) */;\n",
      "  %34 = %33.0 /* ty=Tensor[(1, 4096), float32] */;\n",
      "  %35 = nn.dense(%34, %fc7_weight, units=4096) /* ty=Tensor[(1, 4096), float32] */;\n",
      "  %36 = nn.bias_add(%35, %fc7_bias, axis=-1) /* ty=Tensor[(1, 4096), float32] */;\n",
      "  %37 = nn.relu(%36) /* ty=Tensor[(1, 4096), float32] */;\n",
      "  %38 = nn.dropout(%37) /* ty=(Tensor[(1, 4096), float32], Tensor[(1, 4096), float32]) */;\n",
      "  %39 = %38.0 /* ty=Tensor[(1, 4096), float32] */;\n",
      "  %40 = nn.dense(%39, %fc8_weight, units=1000) /* ty=Tensor[(1, 1000), float32] */;\n",
      "  %41 = nn.bias_add(%40, %fc8_bias, axis=-1) /* ty=Tensor[(1, 1000), float32] */;\n",
      "  nn.softmax(%41) /* ty=Tensor[(1, 1000), float32] */\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "num_class = 1000\n",
    "image_shape = (3, 224, 224)\n",
    "data_shape = (batch_size,) + image_shape\n",
    "out_shape = (batch_size, num_class)\n",
    "\n",
    "mod, params = relay.testing.vgg.get_workload(\n",
    "    num_layers=11, batch_size=batch_size, image_shape=image_shape\n",
    ")\n",
    "\n",
    "# set show_meta_data=True if you want to show meta data\n",
    "print(mod.astext(show_meta_data=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "017f5ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.\n",
      "[14:25:07] /home/wendell/Desktop/tvm/src/runtime/threading_backend.cc:320: Warning: more than two frequencies detected!\n"
     ]
    }
   ],
   "source": [
    "opt_level = 3\n",
    "target = 'llvm'\n",
    "with tvm.transform.PassContext(opt_level=opt_level):\n",
    "    lib = relay.build(mod, target, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51ccd726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00099007 0.00100382 0.00100122 0.0010073  0.00100486 0.00098953\n",
      " 0.00098409 0.00099507 0.00104262 0.00100149]\n"
     ]
    }
   ],
   "source": [
    "# create random input\n",
    "dev = tvm.cpu()\n",
    "data = np.random.uniform(-1, 1, size=data_shape).astype(\"float32\")\n",
    "# create module\n",
    "module = graph_executor.GraphModule(lib[\"default\"](dev))\n",
    "# set input and parameters\n",
    "module.set_input(\"data\", data)\n",
    "# run\n",
    "module.run()\n",
    "# get output\n",
    "out = module.get_output(0, tvm.nd.empty(out_shape)).numpy()\n",
    "\n",
    "# Print first 10 elements of output\n",
    "print(out.flatten()[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aa2d81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deploy_lib.tar']\n"
     ]
    }
   ],
   "source": [
    "from tvm.contrib import utils\n",
    "\n",
    "temp = utils.tempdir()\n",
    "path_lib = temp.relpath(\"deploy_lib.tar\")\n",
    "lib.export_library(path_lib)\n",
    "print(temp.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "725ef827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00099007 0.00100382 0.00100122 0.0010073  0.00100486 0.00098953\n",
      " 0.00098409 0.00099507 0.00104262 0.00100149]\n"
     ]
    }
   ],
   "source": [
    "# load the module back.\n",
    "loaded_lib = tvm.runtime.load_module(path_lib)\n",
    "input_data = tvm.nd.array(data)\n",
    "\n",
    "module = graph_executor.GraphModule(loaded_lib[\"default\"](dev))\n",
    "module.run(data=input_data)\n",
    "out_deploy = module.get_output(0).numpy()\n",
    "\n",
    "# Print first 10 elements of output\n",
    "print(out_deploy.flatten()[0:10])\n",
    "\n",
    "# check whether the output from deployed module is consistent with original one\n",
    "tvm.testing.assert_allclose(out_deploy, out, atol=1e-5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
